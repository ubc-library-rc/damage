{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"File manifest tools: Damage \u00b6 Overview \u00b6 Damage (either DAtaMAnifestGEnerator or a wizard, your choice) is a simple multi-platform utility which creates file manifests in a variety of formats. It was created to deal primarily with statistical data, but it also functions as a generalized file manifest tool. Multiple flavours! \u00b6 Damage comes as both a traditional application (with a handy user interface) or as console utility running in your Windows command prompt/PowerShell/bash session. Download the newest binary version of Damage here: Download Damage A created manifest includes, for all file types: The file name Checksum in your choice of hash for the file. Current flavours of hashes are: sha1, sha224, sha256, sha384, sha512, blake2b, blake2s, md5 Encoding, if available (ie, utf-8, windows-1252, etc.) For plain text files , often used for microdata, the utility also produces information on: Minimum line length Maximum line length Number of records Constant records flag (ie, all lines are of the same length) Row and column of non-ASCII characters A count of null characters Flag for DOS/Windows formatting (ie, carriage return + line feed as opposed to just a line feed). For files in SAS, SPSS and Stata formats (ie, .sas7bdat, .sav and .dta) the utility will provide information on: Number of cases (reported as rows) Number of variables (reported as columns) Note that statistical package files will always be reported as rectangular due to the limitations of parsing them. Output formats are: Plain text Comma Separated Value (ie, a spreadsheet), and depending on which application, tab-separated or pipe-separated values JSON. This JSON doesn\u2019t conform to any particular standard, but is valid JSON object \u2014 one object for all the files. The command line program will produce output in the format of: {\"files\":[{file1medata}, {file2metadata}, ...{fileNmetadata}]} But that\u2019s not all! \u00b6 The damage module \u00b6 While standalone pieces of software are what most people will use, the underlying checking mechanism is available as a Python module also called damage which you can use in your own software. Why would I need this? \u00b6 More than ever, the world today revolves around data sharing. Knowing the data that you\u2019ve downloaded is correct is key. For data distributors damage output can be included as a text file with your data so that you and end users can verify and identify what they\u2019ve downloaded Create detailed version notes with one command Manage changes in file structure using digests which are unique to a particular version of a file, instead of relying on easily changeable file names Easily find duplicate files For researchers damage an help with creating descriptive documentation which is required for your research data deposit damage output ensures the integrity of your data set when used by others Detailed software/installation instructions \u00b6 There are many ways to install damage . Which one is best for you depends on your Using pipx \u00b6 Using pipx is the easiest way to make sure things are up-to-date. Use this if you: Are happy using the terminal/command line Are unlikely to use the damage package in your own code pipx install damage Caveats: Although everything will be installed, you will need to invoke the Damage GUI application from the terminal/command line. Such is the price of convenience. Because pipx is also a package manager, this means that you can use pipx itself to update everything using its own update features GUI application only \u00b6 Use the download button above to download the GUI application. Releases may include precompiled damage applications for various plaforms, mostly MacOS and Windows. The availability of stand-alone application (.exe, .app bundle, whatever) will depend on how much spare time I have to compile everything. Installing with pip \u00b6 If you are Python user, you can install in the normal, pythonic way, from PyPi: pip install damage And if you want to use a particular branch, commit, or some other specialized branch: pip install git+https://github.com/ubc-library-rc/damage.git@master Note that the parts after .git can be customized to whatever you need. Installing with pip makes the package code easily available in your own software. Documentation on the module is available via the API reference documentation . Source code \u00b6 As you may have surmised from the example above, source code is available at https://github.com/ubc-library-rc/damage , along with all of the documentation and binary files. That will likely not surprise you if you are reading this.","title":"Damage: file manifest tools"},{"location":"#file-manifest-tools-damage","text":"","title":"File manifest tools: Damage"},{"location":"#overview","text":"Damage (either DAtaMAnifestGEnerator or a wizard, your choice) is a simple multi-platform utility which creates file manifests in a variety of formats. It was created to deal primarily with statistical data, but it also functions as a generalized file manifest tool.","title":"Overview"},{"location":"#multiple-flavours","text":"Damage comes as both a traditional application (with a handy user interface) or as console utility running in your Windows command prompt/PowerShell/bash session. Download the newest binary version of Damage here: Download Damage A created manifest includes, for all file types: The file name Checksum in your choice of hash for the file. Current flavours of hashes are: sha1, sha224, sha256, sha384, sha512, blake2b, blake2s, md5 Encoding, if available (ie, utf-8, windows-1252, etc.) For plain text files , often used for microdata, the utility also produces information on: Minimum line length Maximum line length Number of records Constant records flag (ie, all lines are of the same length) Row and column of non-ASCII characters A count of null characters Flag for DOS/Windows formatting (ie, carriage return + line feed as opposed to just a line feed). For files in SAS, SPSS and Stata formats (ie, .sas7bdat, .sav and .dta) the utility will provide information on: Number of cases (reported as rows) Number of variables (reported as columns) Note that statistical package files will always be reported as rectangular due to the limitations of parsing them. Output formats are: Plain text Comma Separated Value (ie, a spreadsheet), and depending on which application, tab-separated or pipe-separated values JSON. This JSON doesn\u2019t conform to any particular standard, but is valid JSON object \u2014 one object for all the files. The command line program will produce output in the format of: {\"files\":[{file1medata}, {file2metadata}, ...{fileNmetadata}]}","title":"Multiple flavours!"},{"location":"#but-thats-not-all","text":"","title":"But that&rsquo;s not all!"},{"location":"#the-damage-module","text":"While standalone pieces of software are what most people will use, the underlying checking mechanism is available as a Python module also called damage which you can use in your own software.","title":"The damage module"},{"location":"#why-would-i-need-this","text":"More than ever, the world today revolves around data sharing. Knowing the data that you\u2019ve downloaded is correct is key. For data distributors damage output can be included as a text file with your data so that you and end users can verify and identify what they\u2019ve downloaded Create detailed version notes with one command Manage changes in file structure using digests which are unique to a particular version of a file, instead of relying on easily changeable file names Easily find duplicate files For researchers damage an help with creating descriptive documentation which is required for your research data deposit damage output ensures the integrity of your data set when used by others","title":"Why would I need this?"},{"location":"#detailed-softwareinstallation-instructions","text":"There are many ways to install damage . Which one is best for you depends on your","title":"Detailed software/installation instructions"},{"location":"#using-pipx","text":"Using pipx is the easiest way to make sure things are up-to-date. Use this if you: Are happy using the terminal/command line Are unlikely to use the damage package in your own code pipx install damage Caveats: Although everything will be installed, you will need to invoke the Damage GUI application from the terminal/command line. Such is the price of convenience. Because pipx is also a package manager, this means that you can use pipx itself to update everything using its own update features","title":"Using pipx"},{"location":"#gui-application-only","text":"Use the download button above to download the GUI application. Releases may include precompiled damage applications for various plaforms, mostly MacOS and Windows. The availability of stand-alone application (.exe, .app bundle, whatever) will depend on how much spare time I have to compile everything.","title":"GUI application only"},{"location":"#installing-with-pip","text":"If you are Python user, you can install in the normal, pythonic way, from PyPi: pip install damage And if you want to use a particular branch, commit, or some other specialized branch: pip install git+https://github.com/ubc-library-rc/damage.git@master Note that the parts after .git can be customized to whatever you need. Installing with pip makes the package code easily available in your own software. Documentation on the module is available via the API reference documentation .","title":"Installing with pip"},{"location":"#source-code","text":"As you may have surmised from the example above, source code is available at https://github.com/ubc-library-rc/damage , along with all of the documentation and binary files. That will likely not surprise you if you are reading this.","title":"Source code"},{"location":"api_reference/","text":"API Reference \u00b6 damage \u00b6 Manifest generator for data files. Produces a text file with user specificied checksums for all files from the top of a specified tree and checks line length and ASCII character status for text files. For statistics program files: SAS .sas7bdat SPSS .sav Stata .dta Checker() will report number of cases and variables as rows and columns respectively. Checker \u00b6 A collection of various tools attached to a file Source code in src/damage/__init__.py class Checker(): ''' A collection of various tools attached to a file ''' def __init__(self, fname: str, **kwargs) -> None: #DONE, ''' Initializes Checker instance Parameters ---------- fname : str Path to file **kwargs : dict Additional keyword parameters Other parameters ---------------- weight : bool Weight towards a specific encoding target_encoding : str Specific target encoding, like 'cp1252' ''' #Commercial stats files extensions #I am aware that extension checking is not perfect self.statfiles = ['.dta', '.sav', '.sas7bdat'] #brute force is best force self.textfiles= ['.dat', '.txt', '.md', '.csv', '.tsv', '.asc', '.html', '.xml', '.xsd', '.htm', '.log', '.nfo', '.text', '.xsl', '.py', '.r', '.toml', '.yaml', '.yml', '.prn', '.data'] self.fname = pathlib.Path(fname) #self._ext = fname.suffix self.__istext = self.__istextfile() self.__text_obj = None with tqdm.tqdm(total=self.fname.stat().st_size, desc=f'Loading {self.fname.name}') as pbar: self.__fobj_bin = io.BytesIO() with open(self.fname, 'rb') as f: bsize=2**16 fblock = f.read(bsize) pbar.update(bsize) while fblock: self.__fobj_bin.write(fblock) pbar.update(bsize) fblock = f.read(bsize) self.encoding = self.__encoding(**kwargs) #Using RAM speeds it up by several orders of magnitude if self.__istext: self.__text_obj = io.StringIO(self.__fobj_bin.getvalue().decode( self.encoding.get('encoding', 'utf-8'))) self.__fobj_bin.seek(0) @property def hidden(self)->bool: ''' Returns True if file is hidden (ie, startswith '.') or is in in a hidden directory (ie, any directory on the path starts with '.') ''' if any(x.startswith('.') for x in self.fname.parts): return True return False def __istextfile(self): ''' Check to see if file is a text file based on mimetype. It's not perfect but at least it's something. ''' try: if ('text' in mimetypes.guess_file_type(self.fname) or self.fname.suffix.lower() in self.textfiles): return True except AttributeError: #soft deprecation fix if ('text' in mimetypes.guess_type(self.fname) or self.fname.suffix.lower() in self.textfiles): return True return False def __encoding(self, weight:bool=True,#pylint: disable=unused-argument target:str='cp1252', **kwargs:dict)-> dict: ''' Returns most likely encoding of self.fname, dict with keys encoding, confidence, language and sets Checker.__is_text. It will make the assumption that if cp1252 (Windows-1252) is in the top 3, it *is* Windows-1252. Turn off this behaviour with 'weight' Parameters ---------- weight : bool, default=True target : str, default='cp1252' If weight is True, if target appears in the top three encodings then the encoding will be assigned as target. **kwargs : dict Other miscellaneous things that may have been passed. They will be ignored. Notes ----- Defaults to cp1252 because this was written to deal largely with Statistics Canada material, and that's in English or French. And apparently UTF-8 is too modern for them. ''' encoding = {} read_position = 0 enc_raw = charset_normalizer.from_bytes(self.__fobj_bin.getvalue()) encoding['encoding'] = enc_raw.best().encoding if weight: if target in [x.encoding for x in enc_raw][:3]: read_position = [x.encoding for x in enc_raw][:3].index(target) print(f'read position:{read_position}') encoding['encoding'] = enc_raw[read_position].encoding encoding['language'] = enc_raw[read_position].language #Ripped straight from charset_normalizer source #confidence = 1.0 - r.chaos if r is not None else None encoding['confidence'] = 1.0 - enc_raw[read_position].chaos if self.__istext: return encoding return {'encoding': None, 'confidence': 0.0, 'language' : ''} def __del__(self) -> None:#DONE ''' Destructor closes file ''' self.__fobj_bin.close() def produce_digest(self, prot: str = 'md5', blocksize: int = 2**16) -> str: #DONE ''' Returns hex digest for object Parameters ---------- prot : str, default='md5' Hash type. Supported hashes: 'sha1', 'sha224', 'sha256', 'sha384', 'sha512', 'blake2b', 'blake2s', 'md5'. blocksize : int Read block size in bytes ''' ok_hash = {'sha1' : hashlib.sha1(), 'sha224' : hashlib.sha224(), 'sha256' : hashlib.sha256(), 'sha384' : hashlib.sha384(), 'sha512' : hashlib.sha512(), 'blake2b' : hashlib.blake2b(), 'blake2s' : hashlib.blake2s(), 'md5': hashlib.md5()} self.__fobj_bin.seek(0) try: _hash = ok_hash[prot] except (UnboundLocalError, KeyError): message = ('Unsupported hash type. Valid values are ' f'{list(ok_hash)}.') LOGGER.exception('Unsupported hash type. Valid values are %s', message) raise fblock = self.__fobj_bin.read(blocksize) while fblock: _hash.update(fblock) fblock = self.__fobj_bin.read(blocksize) return _hash.hexdigest() def flat_tester(self, **kwargs) -> dict: #DONE ''' Checks file for line length and number of records. Returns a dictionary: `{'min_cols': int, 'max_cols' : int, 'numrec':int, 'constant' : bool}` ''' if not kwargs.get('flatfile'): return {'min_cols': 'N/A', 'max_cols': 'N/A', 'numrec' : 'N/A', 'constant': 'N/A', 'encoding' : 'N/A'} if self.fname.suffix.lower() in self.statfiles: return self._flat_tester_commercial(**kwargs) if self.__istext: return self._flat_tester_txt() #this should not happen but you never know return {'min_cols': 'N/A', 'max_cols': 'N/A', 'numrec' : 'N/A', 'constant': 'N/A', 'encoding' : 'N/A'} def _flat_tester_commercial(self, **kwargs) -> dict: #DONE ''' Checks SPSS sav, SAS sas7bdat and Stata .dta files for rectangularity Returns a dictionary: `{'min_cols': int, 'max_cols': int, 'numrec' : int, 'constant': True, 'encoding': str}` These files are by definition rectanglar, at least as checked here by pyreadstat/pandas, so constant will always == True. Parameters ---------- **kwargs : dict flatfile : bool If not flatfile check will be ignored ''' if not kwargs.get('flatfile'): return {'min_cols': 'N/A', 'max_cols': 'N/A', 'numrec' : 'N/A', 'constant': 'N/A', 'encoding': 'N/A'} options = {'.sav' : pyreadstat.read_sav, '.dta' : pyreadstat.read_dta, '.sas7bdat' : pyreadstat.read_sas7bdat} #Note: Pyreadstat is written in C, and the C library #asks for file paths, so good luck getting it to read a BytesIO object start = time.perf_counter() #There is no obvious way to get a tqdm progress bar for this operation #short of reprogramming the C code, and that's not going to happen. #So you get this. print(f'Analyzing statistical package file {self.fname}.', file=sys.stderr, end=' ') #-------- #Use multiprocessing, because no one can wait two hours to process #a single large file _, meta = pyreadstat.read_file_multiprocessing( read_function=options[self.fname.suffix.lower()], file_path=self.fname, num_processes=multiprocessing.cpu_count()) #----------- finish = time.perf_counter() print(f'Elapsed time: {round(finish - start, 2)} seconds.', file=sys.stderr) self.encoding['encoding'] = meta.file_encoding return {'min_cols':meta.number_columns, 'max_cols':meta.number_columns, #'numrec': len(content), 'numrec': meta.number_rows, 'constant':True, 'encoding': self.encoding['encoding']} def _flat_tester_txt(self) -> dict: #DONE ''' Checks file for line length and number of records. Returns a dictionary: `{'min_cols': int, 'max_cols' : int, 'numrec':int, 'constant' : bool}` ''' linecount = 0 self.__text_obj.seek(0) if not self.__istext: raise TypeError('Not a text file') maxline = len(self.__text_obj.readline()) minline = maxline orig = maxline # baseline to which new values are compared for row in self.__text_obj.readlines(): linecount += 1 maxline = max(maxline, len(row)) minline = min(minline, len(row)) constant = bool(maxline == orig == minline) self.__text_obj.seek(0) return {'min_cols': minline, 'max_cols': maxline, 'numrec' : linecount, 'constant': constant, 'encoding': self.encoding['encoding']} def non_ascii_tester(self, **kwargs) -> list: #DONE ''' Returns a list of dicts of positions of non-ASCII characters in a text file. Parameters ---------- **kwargs: dict Other parameters ---------------- fname : str Path/filename flatfile : bool Boolean representing a flat ascii file asctest : bool Perform character check, if the file is a text file Returns ------- `[{'row': int, 'col':int, 'char':str}...]` Notes ----- returns [] if not self.__istext ''' if (not kwargs.get('asctest', False)#AAAGH or not self.__istext or not kwargs.get('flatfile')): return [] outlist = [] total = self.__text_obj.getvalue().count('\\n')+1 self.__text_obj.seek(0) for rown, row in tqdm.tqdm(enumerate(self.__text_obj), total=total, desc=f'Non-ASCII character check for {self.fname.name}'): for coln, char in enumerate(row): if char not in string.printable and char != '\\x00': non_asc = {'row':rown+1, 'col': coln+1, 'char':char} outlist.append(non_asc) self.__text_obj.seek(0) return outlist def null_count(self, **kwargs) -> dict: #DONE ''' Returns an integer count of null characters in the file ('\\x00') or None if skipped Parameters ---------- **kwargs : dict Other parameters ---------------- flatfile : bool Test is useless if not a text file. If False, returns 'N/A' ''' if (not kwargs.get('flatfile') or not self.__istext or not kwargs.get('null_chars')): return None if '\\x00' in self.__text_obj.getvalue(): return self.__text_obj.getvalue().count('\\x00') return None def dos(self, **kwargs) -> bool: #DONE ''' Checks for presence of carriage returns in file Returns True if a carriage return ie, ord(13) is present Parameters ---------- **kwargs : dict Other parameters ---------------- flatfile : bool Perform rectangularity check. If False, returns dictionary with all values as 'N/A' ''' if not kwargs.get('flatfile') or not self.__istext: return None return b'\\r\\n' in self.__fobj_bin.getvalue() def _mime_type(self, fname:pathlib.Path)->tuple: ''' Returns mimetype or 'application/octet-stream' Parameters --------- fname : pathlib.Path pathlib.Path to file ''' try: out = mimetypes.guess_file_type(fname, strict=False)[0] except AttributeError: #soft deprecation out = mimetypes.guess_type(fname)[0] if not out: out = 'application/octet-stream' return out def _report(self, **kwargs) -> dict: #DONE ''' Returns a dictionary of outputs based on keywords below. Performs each test and returns the appropriate values. A convenience function so that you don't have to run the tests individually. Parameters ---------- **kwargs : dict digest : str Hash algorithm. Default 'md5' flat : bool Flat file checking. nonascii : bool Check for non-ASCII characters. flatfile : bool Perform rectangularity check. If False, returns dictionary with all values as 'N/A' null_chars : bool Check for null characters Notes ----- Sample output: ``` {'filename':'/tmp/test.csv', 'flat': True, 'min_cols': 100, 'max_cols': 100, 'numrec' : 101, 'constant': True, 'nonascii':False, 'dos':False} ``` ''' out = {'filename': self.fname} digest = kwargs.get('digest', 'md5') #dos = kwargs.get('dos') update_these = [ {'digestType' : digest}, {'digest' : self.produce_digest(digest)}, #OK self.flat_tester(**kwargs), #OK {'nonascii': self.non_ascii_tester(**kwargs)}, # Slow but acceptable {'encoding': self.encoding['encoding']}, #OK {'null_chars': self.null_count(**kwargs)}, #Not great, but better {'mimetype': self._mime_type(self.fname)}, #OK {'dos': self.dos(**kwargs)}] #for upd in tqdm.tqdm(update_these, desc='Processing'): for upd in update_these: out.update(upd) return out def _manifest_txt(self, **kwargs)->str: ''' Returns manifest as plain text Parameters ---------- **kwargs : dict ''' return '\\n'.join([f'{k}: {v}' for k,v in kwargs['report'].items() if v not in ['', None]]) def _manifest_json(self, **kwargs)->str: ''' Returns manifest as JSON Parameters ---------- **kwargs : dict ''' out = kwargs['report'].copy() out['filename'] = str(kwargs['report']['filename']) return json.dumps(out) def _manifest_csv(self, **kwargs)->str: ''' Returns manifest as [whatever]-separated value Parameters ---------- **kwargs : dict ''' outstr = io.StringIO(newline='') writer = csv.DictWriter(outstr, fieldnames=kwargs['report'].keys(), delimiter=kwargs.get('sep', ','), quoting=csv.QUOTE_MINIMAL) if kwargs.get('headers'): writer.writeheader() writer.writerow(kwargs['report']) outstr.seek(0) return outstr.read() def manifest(self, **kwargs) -> str: #really as str #DONE ''' Returns desired output type as string Parameters ---------- **kwargs : dict Other parameters ---------------- out : str Acceptable values are 'txt', 'json', 'csv' 'txt' Plain text 'json' JSON 'csv' Comma-separated value digest : str Hash algorithm. Default 'md5' flat : bool Flat file checking. Default True nonascii : bool Check for non-ASCII characters. Default True dos : bool check for Windows CR/LF combo. Default True flatfile : bool Perform rectangularity check. If False, returns dictionary with all values as 'N/A' headers : bool, default=False Include csv header (only has any effect with out='csv') sep : str Separator if you want a different plain text separator like a tab (\\t) or pipe (|). Only functional with csv output, obviously. ''' report = self._report(**kwargs) report_type={'txt': self._manifest_txt, 'json': self._manifest_json, 'csv': self._manifest_csv, 'tsv': self._manifest_csv, 'psv': self._manifest_csv} try: return report_type[kwargs['out']](report=report, **kwargs) except KeyError: LOGGER.error('Unsupported manifest type %s; defaulting to text', kwargs['out']) return report_type[kwargs['out']](report=report, out='txt', **kwargs) hidden property \u00b6 Returns True if file is hidden (ie, startswith \u2018.\u2019) or is in in a hidden directory (ie, any directory on the path starts with \u2018.\u2019) __del__() \u00b6 Destructor closes file Source code in src/damage/__init__.py def __del__(self) -> None:#DONE ''' Destructor closes file ''' self.__fobj_bin.close() __encoding(weight=True, target='cp1252', **kwargs) \u00b6 Returns most likely encoding of self.fname, dict with keys encoding, confidence, language and sets Checker.__is_text. It will make the assumption that if cp1252 (Windows-1252) is in the top 3, it is Windows-1252. Turn off this behaviour with \u2018weight\u2019 Parameters: weight ( bool , default: True ) \u2013 target ( str , default: 'cp1252' ) \u2013 If weight is True, if target appears in the top three encodings then the encoding will be assigned as target. **kwargs ( dict , default: {} ) \u2013 Other miscellaneous things that may have been passed. They will be ignored. Notes Defaults to cp1252 because this was written to deal largely with Statistics Canada material, and that\u2019s in English or French. And apparently UTF-8 is too modern for them. Source code in src/damage/__init__.py def __encoding(self, weight:bool=True,#pylint: disable=unused-argument target:str='cp1252', **kwargs:dict)-> dict: ''' Returns most likely encoding of self.fname, dict with keys encoding, confidence, language and sets Checker.__is_text. It will make the assumption that if cp1252 (Windows-1252) is in the top 3, it *is* Windows-1252. Turn off this behaviour with 'weight' Parameters ---------- weight : bool, default=True target : str, default='cp1252' If weight is True, if target appears in the top three encodings then the encoding will be assigned as target. **kwargs : dict Other miscellaneous things that may have been passed. They will be ignored. Notes ----- Defaults to cp1252 because this was written to deal largely with Statistics Canada material, and that's in English or French. And apparently UTF-8 is too modern for them. ''' encoding = {} read_position = 0 enc_raw = charset_normalizer.from_bytes(self.__fobj_bin.getvalue()) encoding['encoding'] = enc_raw.best().encoding if weight: if target in [x.encoding for x in enc_raw][:3]: read_position = [x.encoding for x in enc_raw][:3].index(target) print(f'read position:{read_position}') encoding['encoding'] = enc_raw[read_position].encoding encoding['language'] = enc_raw[read_position].language #Ripped straight from charset_normalizer source #confidence = 1.0 - r.chaos if r is not None else None encoding['confidence'] = 1.0 - enc_raw[read_position].chaos if self.__istext: return encoding return {'encoding': None, 'confidence': 0.0, 'language' : ''} __init__(fname, **kwargs) \u00b6 Initializes Checker instance Parameters: fname ( str ) \u2013 Path to file **kwargs ( dict , default: {} ) \u2013 Additional keyword parameters weight ( bool ) \u2013 Weight towards a specific encoding target_encoding ( str ) \u2013 Specific target encoding, like \u2018cp1252\u2019 Source code in src/damage/__init__.py def __init__(self, fname: str, **kwargs) -> None: #DONE, ''' Initializes Checker instance Parameters ---------- fname : str Path to file **kwargs : dict Additional keyword parameters Other parameters ---------------- weight : bool Weight towards a specific encoding target_encoding : str Specific target encoding, like 'cp1252' ''' #Commercial stats files extensions #I am aware that extension checking is not perfect self.statfiles = ['.dta', '.sav', '.sas7bdat'] #brute force is best force self.textfiles= ['.dat', '.txt', '.md', '.csv', '.tsv', '.asc', '.html', '.xml', '.xsd', '.htm', '.log', '.nfo', '.text', '.xsl', '.py', '.r', '.toml', '.yaml', '.yml', '.prn', '.data'] self.fname = pathlib.Path(fname) #self._ext = fname.suffix self.__istext = self.__istextfile() self.__text_obj = None with tqdm.tqdm(total=self.fname.stat().st_size, desc=f'Loading {self.fname.name}') as pbar: self.__fobj_bin = io.BytesIO() with open(self.fname, 'rb') as f: bsize=2**16 fblock = f.read(bsize) pbar.update(bsize) while fblock: self.__fobj_bin.write(fblock) pbar.update(bsize) fblock = f.read(bsize) self.encoding = self.__encoding(**kwargs) #Using RAM speeds it up by several orders of magnitude if self.__istext: self.__text_obj = io.StringIO(self.__fobj_bin.getvalue().decode( self.encoding.get('encoding', 'utf-8'))) self.__fobj_bin.seek(0) __istextfile() \u00b6 Check to see if file is a text file based on mimetype. It\u2019s not perfect but at least it\u2019s something. Source code in src/damage/__init__.py def __istextfile(self): ''' Check to see if file is a text file based on mimetype. It's not perfect but at least it's something. ''' try: if ('text' in mimetypes.guess_file_type(self.fname) or self.fname.suffix.lower() in self.textfiles): return True except AttributeError: #soft deprecation fix if ('text' in mimetypes.guess_type(self.fname) or self.fname.suffix.lower() in self.textfiles): return True return False dos(**kwargs) \u00b6 Checks for presence of carriage returns in file Returns True if a carriage return ie, ord(13) is present Parameters: **kwargs ( dict , default: {} ) \u2013 flatfile ( bool ) \u2013 Perform rectangularity check. If False, returns dictionary with all values as \u2018N/A\u2019 Source code in src/damage/__init__.py def dos(self, **kwargs) -> bool: #DONE ''' Checks for presence of carriage returns in file Returns True if a carriage return ie, ord(13) is present Parameters ---------- **kwargs : dict Other parameters ---------------- flatfile : bool Perform rectangularity check. If False, returns dictionary with all values as 'N/A' ''' if not kwargs.get('flatfile') or not self.__istext: return None return b'\\r\\n' in self.__fobj_bin.getvalue() flat_tester(**kwargs) \u00b6 Checks file for line length and number of records. Returns a dictionary: {'min_cols': int, 'max_cols' : int, 'numrec':int, 'constant' : bool} Source code in src/damage/__init__.py def flat_tester(self, **kwargs) -> dict: #DONE ''' Checks file for line length and number of records. Returns a dictionary: `{'min_cols': int, 'max_cols' : int, 'numrec':int, 'constant' : bool}` ''' if not kwargs.get('flatfile'): return {'min_cols': 'N/A', 'max_cols': 'N/A', 'numrec' : 'N/A', 'constant': 'N/A', 'encoding' : 'N/A'} if self.fname.suffix.lower() in self.statfiles: return self._flat_tester_commercial(**kwargs) if self.__istext: return self._flat_tester_txt() #this should not happen but you never know return {'min_cols': 'N/A', 'max_cols': 'N/A', 'numrec' : 'N/A', 'constant': 'N/A', 'encoding' : 'N/A'} manifest(**kwargs) \u00b6 Returns desired output type as string Parameters: **kwargs ( dict , default: {} ) \u2013 out ( str ) \u2013 Acceptable values are \u2018txt\u2019, \u2018json\u2019, \u2018csv\u2019 \u2018txt\u2019 Plain text \u2018json\u2019 JSON \u2018csv\u2019 Comma-separated value digest ( str ) \u2013 Hash algorithm. Default \u2018md5\u2019 flat ( bool ) \u2013 Flat file checking. Default True nonascii ( bool ) \u2013 Check for non-ASCII characters. Default True dos ( bool ) \u2013 check for Windows CR/LF combo. Default True flatfile ( bool ) \u2013 Perform rectangularity check. If False, returns dictionary with all values as \u2018N/A\u2019 headers ( bool ) \u2013 Include csv header (only has any effect with out=\u2019csv\u2019) sep ( str ) \u2013 Separator if you want a different plain text separator like a tab ( ) or pipe (|). Only functional with csv output, obviously. Source code in src/damage/__init__.py def manifest(self, **kwargs) -> str: #really as str #DONE ''' Returns desired output type as string Parameters ---------- **kwargs : dict Other parameters ---------------- out : str Acceptable values are 'txt', 'json', 'csv' 'txt' Plain text 'json' JSON 'csv' Comma-separated value digest : str Hash algorithm. Default 'md5' flat : bool Flat file checking. Default True nonascii : bool Check for non-ASCII characters. Default True dos : bool check for Windows CR/LF combo. Default True flatfile : bool Perform rectangularity check. If False, returns dictionary with all values as 'N/A' headers : bool, default=False Include csv header (only has any effect with out='csv') sep : str Separator if you want a different plain text separator like a tab (\\t) or pipe (|). Only functional with csv output, obviously. ''' report = self._report(**kwargs) report_type={'txt': self._manifest_txt, 'json': self._manifest_json, 'csv': self._manifest_csv, 'tsv': self._manifest_csv, 'psv': self._manifest_csv} try: return report_type[kwargs['out']](report=report, **kwargs) except KeyError: LOGGER.error('Unsupported manifest type %s; defaulting to text', kwargs['out']) return report_type[kwargs['out']](report=report, out='txt', **kwargs) non_ascii_tester(**kwargs) \u00b6 Returns a list of dicts of positions of non-ASCII characters in a text file. Parameters: **kwargs \u2013 fname ( str ) \u2013 Path/filename flatfile ( bool ) \u2013 Boolean representing a flat ascii file asctest ( bool ) \u2013 Perform character check, if the file is a text file Returns: `[{'row': int, 'col':int, 'char':str}...]` \u2013 Notes returns [] if not self.__istext Source code in src/damage/__init__.py def non_ascii_tester(self, **kwargs) -> list: #DONE ''' Returns a list of dicts of positions of non-ASCII characters in a text file. Parameters ---------- **kwargs: dict Other parameters ---------------- fname : str Path/filename flatfile : bool Boolean representing a flat ascii file asctest : bool Perform character check, if the file is a text file Returns ------- `[{'row': int, 'col':int, 'char':str}...]` Notes ----- returns [] if not self.__istext ''' if (not kwargs.get('asctest', False)#AAAGH or not self.__istext or not kwargs.get('flatfile')): return [] outlist = [] total = self.__text_obj.getvalue().count('\\n')+1 self.__text_obj.seek(0) for rown, row in tqdm.tqdm(enumerate(self.__text_obj), total=total, desc=f'Non-ASCII character check for {self.fname.name}'): for coln, char in enumerate(row): if char not in string.printable and char != '\\x00': non_asc = {'row':rown+1, 'col': coln+1, 'char':char} outlist.append(non_asc) self.__text_obj.seek(0) return outlist null_count(**kwargs) \u00b6 Returns an integer count of null characters in the file (\u2018\u0000\u2019) or None if skipped Parameters: **kwargs ( dict , default: {} ) \u2013 flatfile ( bool ) \u2013 Test is useless if not a text file. If False, returns \u2018N/A\u2019 Source code in src/damage/__init__.py def null_count(self, **kwargs) -> dict: #DONE ''' Returns an integer count of null characters in the file ('\\x00') or None if skipped Parameters ---------- **kwargs : dict Other parameters ---------------- flatfile : bool Test is useless if not a text file. If False, returns 'N/A' ''' if (not kwargs.get('flatfile') or not self.__istext or not kwargs.get('null_chars')): return None if '\\x00' in self.__text_obj.getvalue(): return self.__text_obj.getvalue().count('\\x00') return None produce_digest(prot='md5', blocksize=2 ** 16) \u00b6 Returns hex digest for object Parameters: prot ( str , default: 'md5' ) \u2013 Hash type. Supported hashes: \u2018sha1\u2019, \u2018sha224\u2019, \u2018sha256\u2019, \u2018sha384\u2019, \u2018sha512\u2019, \u2018blake2b\u2019, \u2018blake2s\u2019, \u2018md5\u2019. blocksize ( int , default: 2 ** 16 ) \u2013 Read block size in bytes Source code in src/damage/__init__.py def produce_digest(self, prot: str = 'md5', blocksize: int = 2**16) -> str: #DONE ''' Returns hex digest for object Parameters ---------- prot : str, default='md5' Hash type. Supported hashes: 'sha1', 'sha224', 'sha256', 'sha384', 'sha512', 'blake2b', 'blake2s', 'md5'. blocksize : int Read block size in bytes ''' ok_hash = {'sha1' : hashlib.sha1(), 'sha224' : hashlib.sha224(), 'sha256' : hashlib.sha256(), 'sha384' : hashlib.sha384(), 'sha512' : hashlib.sha512(), 'blake2b' : hashlib.blake2b(), 'blake2s' : hashlib.blake2s(), 'md5': hashlib.md5()} self.__fobj_bin.seek(0) try: _hash = ok_hash[prot] except (UnboundLocalError, KeyError): message = ('Unsupported hash type. Valid values are ' f'{list(ok_hash)}.') LOGGER.exception('Unsupported hash type. Valid values are %s', message) raise fblock = self.__fobj_bin.read(blocksize) while fblock: _hash.update(fblock) fblock = self.__fobj_bin.read(blocksize) return _hash.hexdigest()","title":"API reference"},{"location":"api_reference/#api-reference","text":"","title":"API Reference"},{"location":"api_reference/#damage","text":"Manifest generator for data files. Produces a text file with user specificied checksums for all files from the top of a specified tree and checks line length and ASCII character status for text files. For statistics program files: SAS .sas7bdat SPSS .sav Stata .dta Checker() will report number of cases and variables as rows and columns respectively.","title":"damage"},{"location":"api_reference/#damage.Checker","text":"A collection of various tools attached to a file Source code in src/damage/__init__.py class Checker(): ''' A collection of various tools attached to a file ''' def __init__(self, fname: str, **kwargs) -> None: #DONE, ''' Initializes Checker instance Parameters ---------- fname : str Path to file **kwargs : dict Additional keyword parameters Other parameters ---------------- weight : bool Weight towards a specific encoding target_encoding : str Specific target encoding, like 'cp1252' ''' #Commercial stats files extensions #I am aware that extension checking is not perfect self.statfiles = ['.dta', '.sav', '.sas7bdat'] #brute force is best force self.textfiles= ['.dat', '.txt', '.md', '.csv', '.tsv', '.asc', '.html', '.xml', '.xsd', '.htm', '.log', '.nfo', '.text', '.xsl', '.py', '.r', '.toml', '.yaml', '.yml', '.prn', '.data'] self.fname = pathlib.Path(fname) #self._ext = fname.suffix self.__istext = self.__istextfile() self.__text_obj = None with tqdm.tqdm(total=self.fname.stat().st_size, desc=f'Loading {self.fname.name}') as pbar: self.__fobj_bin = io.BytesIO() with open(self.fname, 'rb') as f: bsize=2**16 fblock = f.read(bsize) pbar.update(bsize) while fblock: self.__fobj_bin.write(fblock) pbar.update(bsize) fblock = f.read(bsize) self.encoding = self.__encoding(**kwargs) #Using RAM speeds it up by several orders of magnitude if self.__istext: self.__text_obj = io.StringIO(self.__fobj_bin.getvalue().decode( self.encoding.get('encoding', 'utf-8'))) self.__fobj_bin.seek(0) @property def hidden(self)->bool: ''' Returns True if file is hidden (ie, startswith '.') or is in in a hidden directory (ie, any directory on the path starts with '.') ''' if any(x.startswith('.') for x in self.fname.parts): return True return False def __istextfile(self): ''' Check to see if file is a text file based on mimetype. It's not perfect but at least it's something. ''' try: if ('text' in mimetypes.guess_file_type(self.fname) or self.fname.suffix.lower() in self.textfiles): return True except AttributeError: #soft deprecation fix if ('text' in mimetypes.guess_type(self.fname) or self.fname.suffix.lower() in self.textfiles): return True return False def __encoding(self, weight:bool=True,#pylint: disable=unused-argument target:str='cp1252', **kwargs:dict)-> dict: ''' Returns most likely encoding of self.fname, dict with keys encoding, confidence, language and sets Checker.__is_text. It will make the assumption that if cp1252 (Windows-1252) is in the top 3, it *is* Windows-1252. Turn off this behaviour with 'weight' Parameters ---------- weight : bool, default=True target : str, default='cp1252' If weight is True, if target appears in the top three encodings then the encoding will be assigned as target. **kwargs : dict Other miscellaneous things that may have been passed. They will be ignored. Notes ----- Defaults to cp1252 because this was written to deal largely with Statistics Canada material, and that's in English or French. And apparently UTF-8 is too modern for them. ''' encoding = {} read_position = 0 enc_raw = charset_normalizer.from_bytes(self.__fobj_bin.getvalue()) encoding['encoding'] = enc_raw.best().encoding if weight: if target in [x.encoding for x in enc_raw][:3]: read_position = [x.encoding for x in enc_raw][:3].index(target) print(f'read position:{read_position}') encoding['encoding'] = enc_raw[read_position].encoding encoding['language'] = enc_raw[read_position].language #Ripped straight from charset_normalizer source #confidence = 1.0 - r.chaos if r is not None else None encoding['confidence'] = 1.0 - enc_raw[read_position].chaos if self.__istext: return encoding return {'encoding': None, 'confidence': 0.0, 'language' : ''} def __del__(self) -> None:#DONE ''' Destructor closes file ''' self.__fobj_bin.close() def produce_digest(self, prot: str = 'md5', blocksize: int = 2**16) -> str: #DONE ''' Returns hex digest for object Parameters ---------- prot : str, default='md5' Hash type. Supported hashes: 'sha1', 'sha224', 'sha256', 'sha384', 'sha512', 'blake2b', 'blake2s', 'md5'. blocksize : int Read block size in bytes ''' ok_hash = {'sha1' : hashlib.sha1(), 'sha224' : hashlib.sha224(), 'sha256' : hashlib.sha256(), 'sha384' : hashlib.sha384(), 'sha512' : hashlib.sha512(), 'blake2b' : hashlib.blake2b(), 'blake2s' : hashlib.blake2s(), 'md5': hashlib.md5()} self.__fobj_bin.seek(0) try: _hash = ok_hash[prot] except (UnboundLocalError, KeyError): message = ('Unsupported hash type. Valid values are ' f'{list(ok_hash)}.') LOGGER.exception('Unsupported hash type. Valid values are %s', message) raise fblock = self.__fobj_bin.read(blocksize) while fblock: _hash.update(fblock) fblock = self.__fobj_bin.read(blocksize) return _hash.hexdigest() def flat_tester(self, **kwargs) -> dict: #DONE ''' Checks file for line length and number of records. Returns a dictionary: `{'min_cols': int, 'max_cols' : int, 'numrec':int, 'constant' : bool}` ''' if not kwargs.get('flatfile'): return {'min_cols': 'N/A', 'max_cols': 'N/A', 'numrec' : 'N/A', 'constant': 'N/A', 'encoding' : 'N/A'} if self.fname.suffix.lower() in self.statfiles: return self._flat_tester_commercial(**kwargs) if self.__istext: return self._flat_tester_txt() #this should not happen but you never know return {'min_cols': 'N/A', 'max_cols': 'N/A', 'numrec' : 'N/A', 'constant': 'N/A', 'encoding' : 'N/A'} def _flat_tester_commercial(self, **kwargs) -> dict: #DONE ''' Checks SPSS sav, SAS sas7bdat and Stata .dta files for rectangularity Returns a dictionary: `{'min_cols': int, 'max_cols': int, 'numrec' : int, 'constant': True, 'encoding': str}` These files are by definition rectanglar, at least as checked here by pyreadstat/pandas, so constant will always == True. Parameters ---------- **kwargs : dict flatfile : bool If not flatfile check will be ignored ''' if not kwargs.get('flatfile'): return {'min_cols': 'N/A', 'max_cols': 'N/A', 'numrec' : 'N/A', 'constant': 'N/A', 'encoding': 'N/A'} options = {'.sav' : pyreadstat.read_sav, '.dta' : pyreadstat.read_dta, '.sas7bdat' : pyreadstat.read_sas7bdat} #Note: Pyreadstat is written in C, and the C library #asks for file paths, so good luck getting it to read a BytesIO object start = time.perf_counter() #There is no obvious way to get a tqdm progress bar for this operation #short of reprogramming the C code, and that's not going to happen. #So you get this. print(f'Analyzing statistical package file {self.fname}.', file=sys.stderr, end=' ') #-------- #Use multiprocessing, because no one can wait two hours to process #a single large file _, meta = pyreadstat.read_file_multiprocessing( read_function=options[self.fname.suffix.lower()], file_path=self.fname, num_processes=multiprocessing.cpu_count()) #----------- finish = time.perf_counter() print(f'Elapsed time: {round(finish - start, 2)} seconds.', file=sys.stderr) self.encoding['encoding'] = meta.file_encoding return {'min_cols':meta.number_columns, 'max_cols':meta.number_columns, #'numrec': len(content), 'numrec': meta.number_rows, 'constant':True, 'encoding': self.encoding['encoding']} def _flat_tester_txt(self) -> dict: #DONE ''' Checks file for line length and number of records. Returns a dictionary: `{'min_cols': int, 'max_cols' : int, 'numrec':int, 'constant' : bool}` ''' linecount = 0 self.__text_obj.seek(0) if not self.__istext: raise TypeError('Not a text file') maxline = len(self.__text_obj.readline()) minline = maxline orig = maxline # baseline to which new values are compared for row in self.__text_obj.readlines(): linecount += 1 maxline = max(maxline, len(row)) minline = min(minline, len(row)) constant = bool(maxline == orig == minline) self.__text_obj.seek(0) return {'min_cols': minline, 'max_cols': maxline, 'numrec' : linecount, 'constant': constant, 'encoding': self.encoding['encoding']} def non_ascii_tester(self, **kwargs) -> list: #DONE ''' Returns a list of dicts of positions of non-ASCII characters in a text file. Parameters ---------- **kwargs: dict Other parameters ---------------- fname : str Path/filename flatfile : bool Boolean representing a flat ascii file asctest : bool Perform character check, if the file is a text file Returns ------- `[{'row': int, 'col':int, 'char':str}...]` Notes ----- returns [] if not self.__istext ''' if (not kwargs.get('asctest', False)#AAAGH or not self.__istext or not kwargs.get('flatfile')): return [] outlist = [] total = self.__text_obj.getvalue().count('\\n')+1 self.__text_obj.seek(0) for rown, row in tqdm.tqdm(enumerate(self.__text_obj), total=total, desc=f'Non-ASCII character check for {self.fname.name}'): for coln, char in enumerate(row): if char not in string.printable and char != '\\x00': non_asc = {'row':rown+1, 'col': coln+1, 'char':char} outlist.append(non_asc) self.__text_obj.seek(0) return outlist def null_count(self, **kwargs) -> dict: #DONE ''' Returns an integer count of null characters in the file ('\\x00') or None if skipped Parameters ---------- **kwargs : dict Other parameters ---------------- flatfile : bool Test is useless if not a text file. If False, returns 'N/A' ''' if (not kwargs.get('flatfile') or not self.__istext or not kwargs.get('null_chars')): return None if '\\x00' in self.__text_obj.getvalue(): return self.__text_obj.getvalue().count('\\x00') return None def dos(self, **kwargs) -> bool: #DONE ''' Checks for presence of carriage returns in file Returns True if a carriage return ie, ord(13) is present Parameters ---------- **kwargs : dict Other parameters ---------------- flatfile : bool Perform rectangularity check. If False, returns dictionary with all values as 'N/A' ''' if not kwargs.get('flatfile') or not self.__istext: return None return b'\\r\\n' in self.__fobj_bin.getvalue() def _mime_type(self, fname:pathlib.Path)->tuple: ''' Returns mimetype or 'application/octet-stream' Parameters --------- fname : pathlib.Path pathlib.Path to file ''' try: out = mimetypes.guess_file_type(fname, strict=False)[0] except AttributeError: #soft deprecation out = mimetypes.guess_type(fname)[0] if not out: out = 'application/octet-stream' return out def _report(self, **kwargs) -> dict: #DONE ''' Returns a dictionary of outputs based on keywords below. Performs each test and returns the appropriate values. A convenience function so that you don't have to run the tests individually. Parameters ---------- **kwargs : dict digest : str Hash algorithm. Default 'md5' flat : bool Flat file checking. nonascii : bool Check for non-ASCII characters. flatfile : bool Perform rectangularity check. If False, returns dictionary with all values as 'N/A' null_chars : bool Check for null characters Notes ----- Sample output: ``` {'filename':'/tmp/test.csv', 'flat': True, 'min_cols': 100, 'max_cols': 100, 'numrec' : 101, 'constant': True, 'nonascii':False, 'dos':False} ``` ''' out = {'filename': self.fname} digest = kwargs.get('digest', 'md5') #dos = kwargs.get('dos') update_these = [ {'digestType' : digest}, {'digest' : self.produce_digest(digest)}, #OK self.flat_tester(**kwargs), #OK {'nonascii': self.non_ascii_tester(**kwargs)}, # Slow but acceptable {'encoding': self.encoding['encoding']}, #OK {'null_chars': self.null_count(**kwargs)}, #Not great, but better {'mimetype': self._mime_type(self.fname)}, #OK {'dos': self.dos(**kwargs)}] #for upd in tqdm.tqdm(update_these, desc='Processing'): for upd in update_these: out.update(upd) return out def _manifest_txt(self, **kwargs)->str: ''' Returns manifest as plain text Parameters ---------- **kwargs : dict ''' return '\\n'.join([f'{k}: {v}' for k,v in kwargs['report'].items() if v not in ['', None]]) def _manifest_json(self, **kwargs)->str: ''' Returns manifest as JSON Parameters ---------- **kwargs : dict ''' out = kwargs['report'].copy() out['filename'] = str(kwargs['report']['filename']) return json.dumps(out) def _manifest_csv(self, **kwargs)->str: ''' Returns manifest as [whatever]-separated value Parameters ---------- **kwargs : dict ''' outstr = io.StringIO(newline='') writer = csv.DictWriter(outstr, fieldnames=kwargs['report'].keys(), delimiter=kwargs.get('sep', ','), quoting=csv.QUOTE_MINIMAL) if kwargs.get('headers'): writer.writeheader() writer.writerow(kwargs['report']) outstr.seek(0) return outstr.read() def manifest(self, **kwargs) -> str: #really as str #DONE ''' Returns desired output type as string Parameters ---------- **kwargs : dict Other parameters ---------------- out : str Acceptable values are 'txt', 'json', 'csv' 'txt' Plain text 'json' JSON 'csv' Comma-separated value digest : str Hash algorithm. Default 'md5' flat : bool Flat file checking. Default True nonascii : bool Check for non-ASCII characters. Default True dos : bool check for Windows CR/LF combo. Default True flatfile : bool Perform rectangularity check. If False, returns dictionary with all values as 'N/A' headers : bool, default=False Include csv header (only has any effect with out='csv') sep : str Separator if you want a different plain text separator like a tab (\\t) or pipe (|). Only functional with csv output, obviously. ''' report = self._report(**kwargs) report_type={'txt': self._manifest_txt, 'json': self._manifest_json, 'csv': self._manifest_csv, 'tsv': self._manifest_csv, 'psv': self._manifest_csv} try: return report_type[kwargs['out']](report=report, **kwargs) except KeyError: LOGGER.error('Unsupported manifest type %s; defaulting to text', kwargs['out']) return report_type[kwargs['out']](report=report, out='txt', **kwargs)","title":"Checker"},{"location":"api_reference/#damage.Checker.hidden","text":"Returns True if file is hidden (ie, startswith \u2018.\u2019) or is in in a hidden directory (ie, any directory on the path starts with \u2018.\u2019)","title":"hidden"},{"location":"api_reference/#damage.Checker.__del__","text":"Destructor closes file Source code in src/damage/__init__.py def __del__(self) -> None:#DONE ''' Destructor closes file ''' self.__fobj_bin.close()","title":"__del__"},{"location":"api_reference/#damage.Checker.__encoding","text":"Returns most likely encoding of self.fname, dict with keys encoding, confidence, language and sets Checker.__is_text. It will make the assumption that if cp1252 (Windows-1252) is in the top 3, it is Windows-1252. Turn off this behaviour with \u2018weight\u2019 Parameters: weight ( bool , default: True ) \u2013 target ( str , default: 'cp1252' ) \u2013 If weight is True, if target appears in the top three encodings then the encoding will be assigned as target. **kwargs ( dict , default: {} ) \u2013 Other miscellaneous things that may have been passed. They will be ignored. Notes Defaults to cp1252 because this was written to deal largely with Statistics Canada material, and that\u2019s in English or French. And apparently UTF-8 is too modern for them. Source code in src/damage/__init__.py def __encoding(self, weight:bool=True,#pylint: disable=unused-argument target:str='cp1252', **kwargs:dict)-> dict: ''' Returns most likely encoding of self.fname, dict with keys encoding, confidence, language and sets Checker.__is_text. It will make the assumption that if cp1252 (Windows-1252) is in the top 3, it *is* Windows-1252. Turn off this behaviour with 'weight' Parameters ---------- weight : bool, default=True target : str, default='cp1252' If weight is True, if target appears in the top three encodings then the encoding will be assigned as target. **kwargs : dict Other miscellaneous things that may have been passed. They will be ignored. Notes ----- Defaults to cp1252 because this was written to deal largely with Statistics Canada material, and that's in English or French. And apparently UTF-8 is too modern for them. ''' encoding = {} read_position = 0 enc_raw = charset_normalizer.from_bytes(self.__fobj_bin.getvalue()) encoding['encoding'] = enc_raw.best().encoding if weight: if target in [x.encoding for x in enc_raw][:3]: read_position = [x.encoding for x in enc_raw][:3].index(target) print(f'read position:{read_position}') encoding['encoding'] = enc_raw[read_position].encoding encoding['language'] = enc_raw[read_position].language #Ripped straight from charset_normalizer source #confidence = 1.0 - r.chaos if r is not None else None encoding['confidence'] = 1.0 - enc_raw[read_position].chaos if self.__istext: return encoding return {'encoding': None, 'confidence': 0.0, 'language' : ''}","title":"__encoding"},{"location":"api_reference/#damage.Checker.__init__","text":"Initializes Checker instance Parameters: fname ( str ) \u2013 Path to file **kwargs ( dict , default: {} ) \u2013 Additional keyword parameters weight ( bool ) \u2013 Weight towards a specific encoding target_encoding ( str ) \u2013 Specific target encoding, like \u2018cp1252\u2019 Source code in src/damage/__init__.py def __init__(self, fname: str, **kwargs) -> None: #DONE, ''' Initializes Checker instance Parameters ---------- fname : str Path to file **kwargs : dict Additional keyword parameters Other parameters ---------------- weight : bool Weight towards a specific encoding target_encoding : str Specific target encoding, like 'cp1252' ''' #Commercial stats files extensions #I am aware that extension checking is not perfect self.statfiles = ['.dta', '.sav', '.sas7bdat'] #brute force is best force self.textfiles= ['.dat', '.txt', '.md', '.csv', '.tsv', '.asc', '.html', '.xml', '.xsd', '.htm', '.log', '.nfo', '.text', '.xsl', '.py', '.r', '.toml', '.yaml', '.yml', '.prn', '.data'] self.fname = pathlib.Path(fname) #self._ext = fname.suffix self.__istext = self.__istextfile() self.__text_obj = None with tqdm.tqdm(total=self.fname.stat().st_size, desc=f'Loading {self.fname.name}') as pbar: self.__fobj_bin = io.BytesIO() with open(self.fname, 'rb') as f: bsize=2**16 fblock = f.read(bsize) pbar.update(bsize) while fblock: self.__fobj_bin.write(fblock) pbar.update(bsize) fblock = f.read(bsize) self.encoding = self.__encoding(**kwargs) #Using RAM speeds it up by several orders of magnitude if self.__istext: self.__text_obj = io.StringIO(self.__fobj_bin.getvalue().decode( self.encoding.get('encoding', 'utf-8'))) self.__fobj_bin.seek(0)","title":"__init__"},{"location":"api_reference/#damage.Checker.__istextfile","text":"Check to see if file is a text file based on mimetype. It\u2019s not perfect but at least it\u2019s something. Source code in src/damage/__init__.py def __istextfile(self): ''' Check to see if file is a text file based on mimetype. It's not perfect but at least it's something. ''' try: if ('text' in mimetypes.guess_file_type(self.fname) or self.fname.suffix.lower() in self.textfiles): return True except AttributeError: #soft deprecation fix if ('text' in mimetypes.guess_type(self.fname) or self.fname.suffix.lower() in self.textfiles): return True return False","title":"__istextfile"},{"location":"api_reference/#damage.Checker.dos","text":"Checks for presence of carriage returns in file Returns True if a carriage return ie, ord(13) is present Parameters: **kwargs ( dict , default: {} ) \u2013 flatfile ( bool ) \u2013 Perform rectangularity check. If False, returns dictionary with all values as \u2018N/A\u2019 Source code in src/damage/__init__.py def dos(self, **kwargs) -> bool: #DONE ''' Checks for presence of carriage returns in file Returns True if a carriage return ie, ord(13) is present Parameters ---------- **kwargs : dict Other parameters ---------------- flatfile : bool Perform rectangularity check. If False, returns dictionary with all values as 'N/A' ''' if not kwargs.get('flatfile') or not self.__istext: return None return b'\\r\\n' in self.__fobj_bin.getvalue()","title":"dos"},{"location":"api_reference/#damage.Checker.flat_tester","text":"Checks file for line length and number of records. Returns a dictionary: {'min_cols': int, 'max_cols' : int, 'numrec':int, 'constant' : bool} Source code in src/damage/__init__.py def flat_tester(self, **kwargs) -> dict: #DONE ''' Checks file for line length and number of records. Returns a dictionary: `{'min_cols': int, 'max_cols' : int, 'numrec':int, 'constant' : bool}` ''' if not kwargs.get('flatfile'): return {'min_cols': 'N/A', 'max_cols': 'N/A', 'numrec' : 'N/A', 'constant': 'N/A', 'encoding' : 'N/A'} if self.fname.suffix.lower() in self.statfiles: return self._flat_tester_commercial(**kwargs) if self.__istext: return self._flat_tester_txt() #this should not happen but you never know return {'min_cols': 'N/A', 'max_cols': 'N/A', 'numrec' : 'N/A', 'constant': 'N/A', 'encoding' : 'N/A'}","title":"flat_tester"},{"location":"api_reference/#damage.Checker.manifest","text":"Returns desired output type as string Parameters: **kwargs ( dict , default: {} ) \u2013 out ( str ) \u2013 Acceptable values are \u2018txt\u2019, \u2018json\u2019, \u2018csv\u2019 \u2018txt\u2019 Plain text \u2018json\u2019 JSON \u2018csv\u2019 Comma-separated value digest ( str ) \u2013 Hash algorithm. Default \u2018md5\u2019 flat ( bool ) \u2013 Flat file checking. Default True nonascii ( bool ) \u2013 Check for non-ASCII characters. Default True dos ( bool ) \u2013 check for Windows CR/LF combo. Default True flatfile ( bool ) \u2013 Perform rectangularity check. If False, returns dictionary with all values as \u2018N/A\u2019 headers ( bool ) \u2013 Include csv header (only has any effect with out=\u2019csv\u2019) sep ( str ) \u2013 Separator if you want a different plain text separator like a tab ( ) or pipe (|). Only functional with csv output, obviously. Source code in src/damage/__init__.py def manifest(self, **kwargs) -> str: #really as str #DONE ''' Returns desired output type as string Parameters ---------- **kwargs : dict Other parameters ---------------- out : str Acceptable values are 'txt', 'json', 'csv' 'txt' Plain text 'json' JSON 'csv' Comma-separated value digest : str Hash algorithm. Default 'md5' flat : bool Flat file checking. Default True nonascii : bool Check for non-ASCII characters. Default True dos : bool check for Windows CR/LF combo. Default True flatfile : bool Perform rectangularity check. If False, returns dictionary with all values as 'N/A' headers : bool, default=False Include csv header (only has any effect with out='csv') sep : str Separator if you want a different plain text separator like a tab (\\t) or pipe (|). Only functional with csv output, obviously. ''' report = self._report(**kwargs) report_type={'txt': self._manifest_txt, 'json': self._manifest_json, 'csv': self._manifest_csv, 'tsv': self._manifest_csv, 'psv': self._manifest_csv} try: return report_type[kwargs['out']](report=report, **kwargs) except KeyError: LOGGER.error('Unsupported manifest type %s; defaulting to text', kwargs['out']) return report_type[kwargs['out']](report=report, out='txt', **kwargs)","title":"manifest"},{"location":"api_reference/#damage.Checker.non_ascii_tester","text":"Returns a list of dicts of positions of non-ASCII characters in a text file. Parameters: **kwargs \u2013 fname ( str ) \u2013 Path/filename flatfile ( bool ) \u2013 Boolean representing a flat ascii file asctest ( bool ) \u2013 Perform character check, if the file is a text file Returns: `[{'row': int, 'col':int, 'char':str}...]` \u2013 Notes returns [] if not self.__istext Source code in src/damage/__init__.py def non_ascii_tester(self, **kwargs) -> list: #DONE ''' Returns a list of dicts of positions of non-ASCII characters in a text file. Parameters ---------- **kwargs: dict Other parameters ---------------- fname : str Path/filename flatfile : bool Boolean representing a flat ascii file asctest : bool Perform character check, if the file is a text file Returns ------- `[{'row': int, 'col':int, 'char':str}...]` Notes ----- returns [] if not self.__istext ''' if (not kwargs.get('asctest', False)#AAAGH or not self.__istext or not kwargs.get('flatfile')): return [] outlist = [] total = self.__text_obj.getvalue().count('\\n')+1 self.__text_obj.seek(0) for rown, row in tqdm.tqdm(enumerate(self.__text_obj), total=total, desc=f'Non-ASCII character check for {self.fname.name}'): for coln, char in enumerate(row): if char not in string.printable and char != '\\x00': non_asc = {'row':rown+1, 'col': coln+1, 'char':char} outlist.append(non_asc) self.__text_obj.seek(0) return outlist","title":"non_ascii_tester"},{"location":"api_reference/#damage.Checker.null_count","text":"Returns an integer count of null characters in the file (\u2018\u0000\u2019) or None if skipped Parameters: **kwargs ( dict , default: {} ) \u2013 flatfile ( bool ) \u2013 Test is useless if not a text file. If False, returns \u2018N/A\u2019 Source code in src/damage/__init__.py def null_count(self, **kwargs) -> dict: #DONE ''' Returns an integer count of null characters in the file ('\\x00') or None if skipped Parameters ---------- **kwargs : dict Other parameters ---------------- flatfile : bool Test is useless if not a text file. If False, returns 'N/A' ''' if (not kwargs.get('flatfile') or not self.__istext or not kwargs.get('null_chars')): return None if '\\x00' in self.__text_obj.getvalue(): return self.__text_obj.getvalue().count('\\x00') return None","title":"null_count"},{"location":"api_reference/#damage.Checker.produce_digest","text":"Returns hex digest for object Parameters: prot ( str , default: 'md5' ) \u2013 Hash type. Supported hashes: \u2018sha1\u2019, \u2018sha224\u2019, \u2018sha256\u2019, \u2018sha384\u2019, \u2018sha512\u2019, \u2018blake2b\u2019, \u2018blake2s\u2019, \u2018md5\u2019. blocksize ( int , default: 2 ** 16 ) \u2013 Read block size in bytes Source code in src/damage/__init__.py def produce_digest(self, prot: str = 'md5', blocksize: int = 2**16) -> str: #DONE ''' Returns hex digest for object Parameters ---------- prot : str, default='md5' Hash type. Supported hashes: 'sha1', 'sha224', 'sha256', 'sha384', 'sha512', 'blake2b', 'blake2s', 'md5'. blocksize : int Read block size in bytes ''' ok_hash = {'sha1' : hashlib.sha1(), 'sha224' : hashlib.sha224(), 'sha256' : hashlib.sha256(), 'sha384' : hashlib.sha384(), 'sha512' : hashlib.sha512(), 'blake2b' : hashlib.blake2b(), 'blake2s' : hashlib.blake2s(), 'md5': hashlib.md5()} self.__fobj_bin.seek(0) try: _hash = ok_hash[prot] except (UnboundLocalError, KeyError): message = ('Unsupported hash type. Valid values are ' f'{list(ok_hash)}.') LOGGER.exception('Unsupported hash type. Valid values are %s', message) raise fblock = self.__fobj_bin.read(blocksize) while fblock: _hash.update(fblock) fblock = self.__fobj_bin.read(blocksize) return _hash.hexdigest()","title":"produce_digest"},{"location":"building_damage_binary/","text":"Creating a binary damage \u00b6 This page will be only of interest to those deciding to build their own application from the source code. For most users, this is unnecessary and the damage console utility can be downloaded from the Github releases page . Note that you need Python and fcheck to do this, and once you do that, you can already invoke damage.py . So this is only necessary if you want to make a binary distribution that you want to give to someone else. Not everyone has a Python installation on their computer, and even if they do, they don\u2019t necessarily know how to use it. As damage is supposed to be simple to use, the easiest way to use it is as a traditional application. This means it needs to be compiled or packaged into, ideally, a single file. Users most likely to require a custom binary version of damage are: Linux users, because the distribution version may not function on their systems Mac users who are using machines with M1 processors Users with ARM chips or other uncommon system architecture To perform these steps, you will need [PyInstaller] along with an installed version of Python >= v3.6. Although these examples use absolute paths, that\u2019s not technically required. You can install PyInstaller the usual way with pip . ie. pip install PyInstaller Building with Pyinstaller \u00b6 Depending on your Python installation, you may need to build with a virtual environment (which you should probably do anyway). Damage doesn\u2019t have a lot of dependencies; you really only need pyreadstat, which installs pandas and numpy as dependencies. or, as the output of pip freeze : altgraph==0.17 importlib-metadata==4.0.1 macholib==1.14 numpy==1.20.2 pandas==1.2.4 pyinstaller==4.3 pyinstaller-hooks-contrib==2021.1 pyreadstat==1.1.0 python-dateutil==2.8.1 pytz==2021.1 six==1.15.0 typing-extensions==3.10.0.0 zipp==3.4.1 pyinstaller -F --additional-hooks-dir ./ --hidden-import pyreadstat._readstat_writer --hidden-import pandas --hidden-import pyreadstat.worker --hidden-import multiprocessing /path/to/damage.py Alternately, you can simplify the PyInstaller command by using the py_install/hook-fcheck.py file: pyinstaller -F --additional-hooks-dir=/path/to/py_install /path/to/damage.py This process will create a damage.spec file along with a build and a dist dir. Inside the dist dir will be your self-contained file, which you can do with as you like. Normally, on MacOS and linux system, the resultant damage file is placed in /usr/local/bin and for Windows computers, the damage.exe file is placed somewhere on you system PATH .","title":"Creating a binary damage"},{"location":"building_damage_binary/#creating-a-binary-damage","text":"This page will be only of interest to those deciding to build their own application from the source code. For most users, this is unnecessary and the damage console utility can be downloaded from the Github releases page . Note that you need Python and fcheck to do this, and once you do that, you can already invoke damage.py . So this is only necessary if you want to make a binary distribution that you want to give to someone else. Not everyone has a Python installation on their computer, and even if they do, they don\u2019t necessarily know how to use it. As damage is supposed to be simple to use, the easiest way to use it is as a traditional application. This means it needs to be compiled or packaged into, ideally, a single file. Users most likely to require a custom binary version of damage are: Linux users, because the distribution version may not function on their systems Mac users who are using machines with M1 processors Users with ARM chips or other uncommon system architecture To perform these steps, you will need [PyInstaller] along with an installed version of Python >= v3.6. Although these examples use absolute paths, that\u2019s not technically required. You can install PyInstaller the usual way with pip . ie. pip install PyInstaller","title":"Creating a binary damage"},{"location":"building_damage_binary/#building-with-pyinstaller","text":"Depending on your Python installation, you may need to build with a virtual environment (which you should probably do anyway). Damage doesn\u2019t have a lot of dependencies; you really only need pyreadstat, which installs pandas and numpy as dependencies. or, as the output of pip freeze : altgraph==0.17 importlib-metadata==4.0.1 macholib==1.14 numpy==1.20.2 pandas==1.2.4 pyinstaller==4.3 pyinstaller-hooks-contrib==2021.1 pyreadstat==1.1.0 python-dateutil==2.8.1 pytz==2021.1 six==1.15.0 typing-extensions==3.10.0.0 zipp==3.4.1 pyinstaller -F --additional-hooks-dir ./ --hidden-import pyreadstat._readstat_writer --hidden-import pandas --hidden-import pyreadstat.worker --hidden-import multiprocessing /path/to/damage.py Alternately, you can simplify the PyInstaller command by using the py_install/hook-fcheck.py file: pyinstaller -F --additional-hooks-dir=/path/to/py_install /path/to/damage.py This process will create a damage.spec file along with a build and a dist dir. Inside the dist dir will be your self-contained file, which you can do with as you like. Normally, on MacOS and linux system, the resultant damage file is placed in /usr/local/bin and for Windows computers, the damage.exe file is placed somewhere on you system PATH .","title":"Building with Pyinstaller"},{"location":"building_damage_gui_app/","text":"Creating your own Damage app \u00b6 This page will be only of interest to those deciding to build their own application from the source code, most likely because their processor (like ARM or M1) is not supported. For most users, this is unnecessary and Damage can be downloaded from the Github releases page . The Damage GUI application, unlike the console program, isn\u2019t included when installing fcheck , either using pip or from the source code itself. Because the Damage app uses tkinter , there are a number of problems that can arise, notably on Mac computers. Should you want to build the app, here are some guidelines on how to go about it. The build process doesn\u2019t use the same Python version as the fcheck module and the console utility. You will note in setup.py that it says python_requires:'>=3.6' . THIS IS NOT (NECESSARILY) TRUE FOR BUILDING THE GUI APP , notably on Mac computers, due to issues with tkinter . The app was built using Python 3.10.2 on Mac. Building the app requires the installation of PyInstaller and PySimpleGUI , as well as the installation of fcheck Procedure \u00b6 Windows and Linux computers \u00b6 For Windows and Linux, the easiest way is to build using the included PyInstaller .spec file. Change to the gui directory and run python3 -m PyInstaller --clean --noconfirm damage_gui_combined.spec If you don\u2019t want to use the premade .spec file: python3 -m PyInstaller --onefile --additional-hooks-dir ../py_install/ --name Damage --clean --noconfirm [any additional options go here] src/damage_gui.py Note that for Windows and Linux, any version of Python >=3.6 should suffice, unlike for Mac computers. The resultant application will be in the dist directory; place it wherever you like, MacOS \u00b6 For Mac computers, you can technically use the same procedure as above. However, it\u2019s a bit redunant for Mac, as there\u2019s no real reason to create the --onefile --windowed version as Mac apps are, by default, directories anyway. The solution is to run PyInstaller without those options, editing the resulting plist file. That is, in the source directory, run PyiInstaller, where python310 is the path to your Python 3.10 or higher Python python310 -m PyInstaller --add-binary='/System/Library/Frameworks/Tk.framework/Tk':'tk' --add-binary='/System/Library/Frameworks/Tcl.framework/Tcl':'tcl' --additional-hooks-dir ../py_install/ --icon=assets/DamageAppIcon.icns --osx-bundle-identifier=ca.ubc.library --target-arch=x86_64 --noconsole --clean --noconfirm --name Damage src/damage_gui.py And then, from the same directory: python310 customize_pyinstaller_plist.py Once that is completed, there will be Mac app bundle in dist which doesn\u2019t require unpacking at runtime. The completed app bundle can then be placed into DMG container for distribution, if required.","title":"Creating your own Damage app"},{"location":"building_damage_gui_app/#creating-your-own-damage-app","text":"This page will be only of interest to those deciding to build their own application from the source code, most likely because their processor (like ARM or M1) is not supported. For most users, this is unnecessary and Damage can be downloaded from the Github releases page . The Damage GUI application, unlike the console program, isn\u2019t included when installing fcheck , either using pip or from the source code itself. Because the Damage app uses tkinter , there are a number of problems that can arise, notably on Mac computers. Should you want to build the app, here are some guidelines on how to go about it. The build process doesn\u2019t use the same Python version as the fcheck module and the console utility. You will note in setup.py that it says python_requires:'>=3.6' . THIS IS NOT (NECESSARILY) TRUE FOR BUILDING THE GUI APP , notably on Mac computers, due to issues with tkinter . The app was built using Python 3.10.2 on Mac. Building the app requires the installation of PyInstaller and PySimpleGUI , as well as the installation of fcheck","title":"Creating your own Damage app"},{"location":"building_damage_gui_app/#procedure","text":"","title":"Procedure"},{"location":"building_damage_gui_app/#windows-and-linux-computers","text":"For Windows and Linux, the easiest way is to build using the included PyInstaller .spec file. Change to the gui directory and run python3 -m PyInstaller --clean --noconfirm damage_gui_combined.spec If you don\u2019t want to use the premade .spec file: python3 -m PyInstaller --onefile --additional-hooks-dir ../py_install/ --name Damage --clean --noconfirm [any additional options go here] src/damage_gui.py Note that for Windows and Linux, any version of Python >=3.6 should suffice, unlike for Mac computers. The resultant application will be in the dist directory; place it wherever you like,","title":"Windows and Linux computers"},{"location":"building_damage_gui_app/#macos","text":"For Mac computers, you can technically use the same procedure as above. However, it\u2019s a bit redunant for Mac, as there\u2019s no real reason to create the --onefile --windowed version as Mac apps are, by default, directories anyway. The solution is to run PyInstaller without those options, editing the resulting plist file. That is, in the source directory, run PyiInstaller, where python310 is the path to your Python 3.10 or higher Python python310 -m PyInstaller --add-binary='/System/Library/Frameworks/Tk.framework/Tk':'tk' --add-binary='/System/Library/Frameworks/Tcl.framework/Tcl':'tcl' --additional-hooks-dir ../py_install/ --icon=assets/DamageAppIcon.icns --osx-bundle-identifier=ca.ubc.library --target-arch=x86_64 --noconsole --clean --noconfirm --name Damage src/damage_gui.py And then, from the same directory: python310 customize_pyinstaller_plist.py Once that is completed, there will be Mac app bundle in dist which doesn\u2019t require unpacking at runtime. The completed app bundle can then be placed into DMG container for distribution, if required.","title":"MacOS"},{"location":"credits/","text":"Credits \u00b6 Contact \u00b6 Damage * was written by Paul Lesack of the University of British Columbia Library Research Commons . Acknowledgements \u00b6 Many thanks to Jeremy Buhler for coming up with the damage name. Reading statistical file metadata is made very simple with pyreadstat . Without pydoc-markdown , mkdocs , documentation would have been a lot harder.","title":"Credits"},{"location":"credits/#credits","text":"","title":"Credits"},{"location":"credits/#contact","text":"Damage * was written by Paul Lesack of the University of British Columbia Library Research Commons .","title":"Contact"},{"location":"credits/#acknowledgements","text":"Many thanks to Jeremy Buhler for coming up with the damage name. Reading statistical file metadata is made very simple with pyreadstat . Without pydoc-markdown , mkdocs , documentation would have been a lot harder.","title":"Acknowledgements"},{"location":"faq/","text":"Frequently asked questions \u00b6 What is the point of this application? Damage is designed to ease the distribution of data by providing a standardized listing of checksums and record lengths, which ideally will be distributed with the data set itself. This allows end-users to duplicate the procedure and compare results. If you\u2019re a data provider Use Damage to create a data manifest which you distribute with your data and documentation. This will allow users to verify that they have exactly what you intend them to have. If you\u2019re a data user Use Damage to verify that what you\u2019ve received from a data provider is what they\u2019re supposed to have given you. Bonus points If both parties shorten file paths and use the same directory structure, then the manifests can be compared. If the checksums of the manifests are not identical, then the data structures are not identical. Why is there no binary version of [release]? Damage is developed off the side of my desk. Compiling can take time away from the other things that need doing, and also requires access to multiple platforms. Why is there no printer dialogue when I print from Damage ? The application prints text directly to default printer; there\u2019s no formatting. For more nicely formatted text, consider opening the output document in a text editor or spreadsheet. I can\u2019t edit values in Damage\u2019s csv mode? This is the expected behaviour. If you need to edit the CSV, please use a spreadsheet application. Why would you call the software \u201cdamage\u201d? Command line utility names are not easy to remember. Typing \u2018damage [filename\u2019] for the first time will burn the name into your memory. Why does the software hang during examination of text files? Most of the time, the software hasn\u2019t actually crashed; it\u2019s still doing its processing, possibly more slowly than one would like. There can be two reasons for this: Every character in a text file is examined; if your file is large, the amount of time this requires is not negligble. There have been instances of file corruption where data is replaced by null characters . Using versions previous to v0.1.3 output the row and column location of every such character, which takes a very long time if there are, as has happened, tens of millions of these characters. Versions >= v0.1.3 changed this behaviour and simply output a count. As of v0.5.0+, the command line version of damage will give you progress meters to let you know what\u2019s happening. Also, it\u2019s way faster. I try to run damage from Windows explorer or Finder and it doesn\u2019t work. What\u2019s going on? If you installed with pipx or pip , make sure you are running the GUI version of damage and not the command line version. Multi-platform capablity is hard. I develop mostly for Mac and Linux, and Windows errors can slip through the cracks. If you are having problems, please report an issue . What\u2019s all this PATH and /usr/local/bin stuff? PATH is an environment variable on your computer which allows programs to invoked without laboriously typing out the full location of the program. On linux-like systems, /usr/local/bin is already part of the PATH environment variable, so just moving/copying the damage executable file there will do all the work in one step. If you are using damage.py , ie, you installed fcheck with pip , you don\u2019t need to do any of this unless you really want to.","title":"Frequently asked questions"},{"location":"faq/#frequently-asked-questions","text":"What is the point of this application? Damage is designed to ease the distribution of data by providing a standardized listing of checksums and record lengths, which ideally will be distributed with the data set itself. This allows end-users to duplicate the procedure and compare results. If you\u2019re a data provider Use Damage to create a data manifest which you distribute with your data and documentation. This will allow users to verify that they have exactly what you intend them to have. If you\u2019re a data user Use Damage to verify that what you\u2019ve received from a data provider is what they\u2019re supposed to have given you. Bonus points If both parties shorten file paths and use the same directory structure, then the manifests can be compared. If the checksums of the manifests are not identical, then the data structures are not identical. Why is there no binary version of [release]? Damage is developed off the side of my desk. Compiling can take time away from the other things that need doing, and also requires access to multiple platforms. Why is there no printer dialogue when I print from Damage ? The application prints text directly to default printer; there\u2019s no formatting. For more nicely formatted text, consider opening the output document in a text editor or spreadsheet. I can\u2019t edit values in Damage\u2019s csv mode? This is the expected behaviour. If you need to edit the CSV, please use a spreadsheet application. Why would you call the software \u201cdamage\u201d? Command line utility names are not easy to remember. Typing \u2018damage [filename\u2019] for the first time will burn the name into your memory. Why does the software hang during examination of text files? Most of the time, the software hasn\u2019t actually crashed; it\u2019s still doing its processing, possibly more slowly than one would like. There can be two reasons for this: Every character in a text file is examined; if your file is large, the amount of time this requires is not negligble. There have been instances of file corruption where data is replaced by null characters . Using versions previous to v0.1.3 output the row and column location of every such character, which takes a very long time if there are, as has happened, tens of millions of these characters. Versions >= v0.1.3 changed this behaviour and simply output a count. As of v0.5.0+, the command line version of damage will give you progress meters to let you know what\u2019s happening. Also, it\u2019s way faster. I try to run damage from Windows explorer or Finder and it doesn\u2019t work. What\u2019s going on? If you installed with pipx or pip , make sure you are running the GUI version of damage and not the command line version. Multi-platform capablity is hard. I develop mostly for Mac and Linux, and Windows errors can slip through the cracks. If you are having problems, please report an issue . What\u2019s all this PATH and /usr/local/bin stuff? PATH is an environment variable on your computer which allows programs to invoked without laboriously typing out the full location of the program. On linux-like systems, /usr/local/bin is already part of the PATH environment variable, so just moving/copying the damage executable file there will do all the work in one step. If you are using damage.py , ie, you installed fcheck with pip , you don\u2019t need to do any of this unless you really want to.","title":"Frequently asked questions"},{"location":"how_to_use_damage/","text":"How to use the Damage console utility \u00b6 Documentation is for the console utility. That means a Windows command prompt or terminal is required for use. The console utility is normally referred to with a lowercase initial \u2018d\u2019 (ie, damage ) and the full GUI application as damage_gui . Whether or not you call the application with a straight damage or python damage.py will depend on how you work, but the first will be more common. Program options \u00b6 usage: damage [-h] [-v] [-o {txt,csv,tsv,json}] [-n] [-r] [-t {md5,sha1,sha224,sha256,sha384,sha512,blake2b,blake2s}] [-a] [-f TO_FILE] files [files ...] Produces a text, csv or JSON output with checksums for files, testing for Windows CRLF combinations, as well as checking text files for regularity and non/ASCII characters positional arguments: files Files to check. Wildcards acceptable (eg, *) options: -h, --help show this help message and exit -v, --version Show version number and exit -o, --output {txt,csv,tsv,json} Output format. One of txt, csv, json, tsv -n, --no-flat Don't check text files for rectangularity -r, --recursive Recursive *directory* processing of file tree. Assumes that the arguments point to a directory (eg, tmp/), and a slash will be appended if one does not exist -t, --hash-type {md5,sha1,sha224,sha256,sha384,sha512,blake2b,blake2s} Checksum hash type. Supported hashes: 'sha1', 'sha224', 'sha256', 'sha384', 'sha512', 'blake2b', 'blake2s', 'md5'. Default: 'md5' -a, --no-ascii Don't check text files for non-ASCII characters -f, --to-file TO_FILE Output to -f [file] instead of stdout Compiling/packaging the software on your platform \u00b6 Making your own damage binary if the supplied ones don\u2019t meet your needs is easy. See the how to create a standalone application page for details.","title":"How to use the Damage console utility"},{"location":"how_to_use_damage/#how-to-use-the-damage-console-utility","text":"Documentation is for the console utility. That means a Windows command prompt or terminal is required for use. The console utility is normally referred to with a lowercase initial \u2018d\u2019 (ie, damage ) and the full GUI application as damage_gui . Whether or not you call the application with a straight damage or python damage.py will depend on how you work, but the first will be more common.","title":"How to use the Damage console utility"},{"location":"how_to_use_damage/#program-options","text":"usage: damage [-h] [-v] [-o {txt,csv,tsv,json}] [-n] [-r] [-t {md5,sha1,sha224,sha256,sha384,sha512,blake2b,blake2s}] [-a] [-f TO_FILE] files [files ...] Produces a text, csv or JSON output with checksums for files, testing for Windows CRLF combinations, as well as checking text files for regularity and non/ASCII characters positional arguments: files Files to check. Wildcards acceptable (eg, *) options: -h, --help show this help message and exit -v, --version Show version number and exit -o, --output {txt,csv,tsv,json} Output format. One of txt, csv, json, tsv -n, --no-flat Don't check text files for rectangularity -r, --recursive Recursive *directory* processing of file tree. Assumes that the arguments point to a directory (eg, tmp/), and a slash will be appended if one does not exist -t, --hash-type {md5,sha1,sha224,sha256,sha384,sha512,blake2b,blake2s} Checksum hash type. Supported hashes: 'sha1', 'sha224', 'sha256', 'sha384', 'sha512', 'blake2b', 'blake2s', 'md5'. Default: 'md5' -a, --no-ascii Don't check text files for non-ASCII characters -f, --to-file TO_FILE Output to -f [file] instead of stdout","title":"Program options"},{"location":"how_to_use_damage/#compilingpackaging-the-software-on-your-platform","text":"Making your own damage binary if the supplied ones don\u2019t meet your needs is easy. See the how to create a standalone application page for details.","title":"Compiling/packaging the software on your platform"},{"location":"how_to_use_gui_damage/","text":"How to use the Damage application \u00b6 Installation \u00b6 For all versions of Damage , download the latest release for your platform from the Github releases page . Note that releases for all architectures are not available, nor will there necessarily be compiled binary releases every time . However, if you install via pipx or pip , you will always get the newest possible release. Using the precompiled binary files \u00b6 The precompiled versions are just \u201cnormal\u201d programs. The command line utility is not included. See the the note if you\u2019ve installed with pipx or pip . For Microsoft Windows \u00b6 The Windows application is a portable file; it does not require installation. Simply unzip it and run damage.exe . Move it to wherever you like; the Program Files directory is a common choice. For MacOS \u00b6 Double-click the DMG file, and it should automatically appear in a Finder window. Drag the icon to the Applications folder. If, for some reason, you don\u2019t want to put it in the Applications folder, you can drag it somewhere else. Note that the developer(s) of Damage do not have an Apple developer account. This means that you may receive a warning about an unidentified developer as per this page: https://support.apple.com/en-ca/guide/mac-help/mh40616/mac . To start the application (for the first time only), you may have to right click on the application, select Open then agree to the conditions. Or whatever it is Apple decide to do, because it changes from release to release. For Linux \u00b6 I no longer have an x86_64 or AMD64 processor Linux OS, so there is no guarantee that Linux will be represented as a download. Such is life. Unzip the download. Like the Windows utility, it is a single file. Traditionally, you can place that file in /usr/local/bin or opt/bin , or if that is not a solution, another user-centred location is ~/.local/bin . Usage \u00b6 On running the application, you will be presented with an essentially blank interface. The workflow consists of the following easy steps: Set your preferences Select files Create the manifest Save (or print) the output The Preferences window \u00b6 The output of Damage , like all other software, will be dependent on the preferences you set. While the defaults are fine, you may need to match your output to someone else\u2019s manifest, or you don\u2019t like what the defaults are. To do this, use the Preferences window, available via the Edit/Preferences menu item. The options Shorten file paths in output : Given a list of files, the common portion of the file path will be removed in the output. For example, given two files path/to/dir_a/x.txt and path/to/dir_b/y.txt , the output will show dir_a/x.txt and dir_b/y.txt . Rectangularity check : For plain text files and statistical software files, check for line length and number of records. If a text file is meant to be a rectangular file, ie, each record or line contains the same number of observations, thus having the same line length, then the output will show constant records , and all the lines will have the same length. In the case of statistical files, the line length refers to the number of fields , ie, variables. If, for instance, the value is not constant, that means that the data set is truncated. Recursively add files from directories : When adding a folder, add all the files found in sub-folders as well. So, if folder A contains folders B and C, any files found in A, B and C will be added, all the way to to the point where no further folders are found. Include hidden files : While there are many ways to hide files, this checkbox will include files that begin with . , such as .DS_Store . Or, if you are using directories, it will include files in directories such as .git . Normally this would be unchecked unless you have a special use case. Hash type : Cryptographic hash algorithm used to check for file integrity. The most commonly used are likely md5 and sha256 . If checking downloaded files for integrity, use the algorithm stated on the download site. For example, on the release page for this software product, you will see that the download checksums are listed as sha256 . If checksums don\u2019t match, then file integrity is compromised. Output format : Output format of the resulting manifest. txt: Human readable plain text format csv: Comma separated value spreadsheet json: Javascript Object Notation dictionary for times when machine readable output is required. Selecting files \u00b6 You have several options to select files to analyze. Add individual files with either the Add Files button or the the menu under Files/Add Files If you would like to add an entire folder of files, select the Add Folder button or the Files/Add Folder menu. Files (with their full paths) will be added to the left sidebar, or File Section . In some cases, what seems like a file doesn\u2019t appear in the list. For instance, should you attempt to add a Mac application (which, in the Finder, looks like a single item), it will be ignored. Mac Applications are really folders, despite looking like single files. Should you really need to add an item such as this, use the Add Folder function. Removing files \u00b6 If you wish to edit the list of files, select the files you wish to remove from the File Section and use the Remove Files button, or use the convenient menu item Files/Remove Files Generating the manifest \u00b6 To generate the manifest for your selected files, hit the Generate Manifest button, use the Actions/Create Manifest menu item, or use the plaform specific short combination. Note that this operation may take a while depending on the size and complexity of the file(s) you are analyzing. Notably, statistical files with hundreds of thousands of records (or millions) may take a while. Don\u2019t assume the application has crashed if results are not instant. Once completed, the output is shown in the cleverly labelled Output Section . At this point, you can edit the results (although it\u2019s not clear why you would). More importantly, though, the saving and printing options will now be available. Output \u00b6 To save, select Actions/Save Output or use the shortcut key combination. The output will be saved with the correct extension automatically. To print, select Actions/Print Output or use the shortcut key combination. The output will be sent immediately to your default printer. Note : There is no printer selection and formatting dialogue; the manifest is sent to the printer as plain text. Note that in the case of csv files, this means that you will get raw csv, not a nice table. If you require nicely tabulated and formatted data, use a spreadsheet to open the created csv file. The Help menu \u00b6 Damage help : takes you to this page. Obviously, this requires an internet connection, but what doesn\u2019t these days Credits and Details : Developer information as well as links to the source code.","title":"How to use the Damage application"},{"location":"how_to_use_gui_damage/#how-to-use-the-damage-application","text":"","title":"How to use the Damage application"},{"location":"how_to_use_gui_damage/#installation","text":"For all versions of Damage , download the latest release for your platform from the Github releases page . Note that releases for all architectures are not available, nor will there necessarily be compiled binary releases every time . However, if you install via pipx or pip , you will always get the newest possible release.","title":"Installation"},{"location":"how_to_use_gui_damage/#using-the-precompiled-binary-files","text":"The precompiled versions are just \u201cnormal\u201d programs. The command line utility is not included. See the the note if you\u2019ve installed with pipx or pip .","title":"Using the precompiled binary files"},{"location":"how_to_use_gui_damage/#for-microsoft-windows","text":"The Windows application is a portable file; it does not require installation. Simply unzip it and run damage.exe . Move it to wherever you like; the Program Files directory is a common choice.","title":"For Microsoft Windows"},{"location":"how_to_use_gui_damage/#for-macos","text":"Double-click the DMG file, and it should automatically appear in a Finder window. Drag the icon to the Applications folder. If, for some reason, you don\u2019t want to put it in the Applications folder, you can drag it somewhere else. Note that the developer(s) of Damage do not have an Apple developer account. This means that you may receive a warning about an unidentified developer as per this page: https://support.apple.com/en-ca/guide/mac-help/mh40616/mac . To start the application (for the first time only), you may have to right click on the application, select Open then agree to the conditions. Or whatever it is Apple decide to do, because it changes from release to release.","title":"For MacOS"},{"location":"how_to_use_gui_damage/#for-linux","text":"I no longer have an x86_64 or AMD64 processor Linux OS, so there is no guarantee that Linux will be represented as a download. Such is life. Unzip the download. Like the Windows utility, it is a single file. Traditionally, you can place that file in /usr/local/bin or opt/bin , or if that is not a solution, another user-centred location is ~/.local/bin .","title":"For Linux"},{"location":"how_to_use_gui_damage/#usage","text":"On running the application, you will be presented with an essentially blank interface. The workflow consists of the following easy steps: Set your preferences Select files Create the manifest Save (or print) the output","title":"Usage"},{"location":"how_to_use_gui_damage/#the-preferences-window","text":"The output of Damage , like all other software, will be dependent on the preferences you set. While the defaults are fine, you may need to match your output to someone else\u2019s manifest, or you don\u2019t like what the defaults are. To do this, use the Preferences window, available via the Edit/Preferences menu item. The options Shorten file paths in output : Given a list of files, the common portion of the file path will be removed in the output. For example, given two files path/to/dir_a/x.txt and path/to/dir_b/y.txt , the output will show dir_a/x.txt and dir_b/y.txt . Rectangularity check : For plain text files and statistical software files, check for line length and number of records. If a text file is meant to be a rectangular file, ie, each record or line contains the same number of observations, thus having the same line length, then the output will show constant records , and all the lines will have the same length. In the case of statistical files, the line length refers to the number of fields , ie, variables. If, for instance, the value is not constant, that means that the data set is truncated. Recursively add files from directories : When adding a folder, add all the files found in sub-folders as well. So, if folder A contains folders B and C, any files found in A, B and C will be added, all the way to to the point where no further folders are found. Include hidden files : While there are many ways to hide files, this checkbox will include files that begin with . , such as .DS_Store . Or, if you are using directories, it will include files in directories such as .git . Normally this would be unchecked unless you have a special use case. Hash type : Cryptographic hash algorithm used to check for file integrity. The most commonly used are likely md5 and sha256 . If checking downloaded files for integrity, use the algorithm stated on the download site. For example, on the release page for this software product, you will see that the download checksums are listed as sha256 . If checksums don\u2019t match, then file integrity is compromised. Output format : Output format of the resulting manifest. txt: Human readable plain text format csv: Comma separated value spreadsheet json: Javascript Object Notation dictionary for times when machine readable output is required.","title":"The Preferences window"},{"location":"how_to_use_gui_damage/#selecting-files","text":"You have several options to select files to analyze. Add individual files with either the Add Files button or the the menu under Files/Add Files If you would like to add an entire folder of files, select the Add Folder button or the Files/Add Folder menu. Files (with their full paths) will be added to the left sidebar, or File Section . In some cases, what seems like a file doesn\u2019t appear in the list. For instance, should you attempt to add a Mac application (which, in the Finder, looks like a single item), it will be ignored. Mac Applications are really folders, despite looking like single files. Should you really need to add an item such as this, use the Add Folder function.","title":"Selecting files"},{"location":"how_to_use_gui_damage/#removing-files","text":"If you wish to edit the list of files, select the files you wish to remove from the File Section and use the Remove Files button, or use the convenient menu item Files/Remove Files","title":"Removing files"},{"location":"how_to_use_gui_damage/#generating-the-manifest","text":"To generate the manifest for your selected files, hit the Generate Manifest button, use the Actions/Create Manifest menu item, or use the plaform specific short combination. Note that this operation may take a while depending on the size and complexity of the file(s) you are analyzing. Notably, statistical files with hundreds of thousands of records (or millions) may take a while. Don\u2019t assume the application has crashed if results are not instant. Once completed, the output is shown in the cleverly labelled Output Section . At this point, you can edit the results (although it\u2019s not clear why you would). More importantly, though, the saving and printing options will now be available.","title":"Generating the manifest"},{"location":"how_to_use_gui_damage/#output","text":"To save, select Actions/Save Output or use the shortcut key combination. The output will be saved with the correct extension automatically. To print, select Actions/Print Output or use the shortcut key combination. The output will be sent immediately to your default printer. Note : There is no printer selection and formatting dialogue; the manifest is sent to the printer as plain text. Note that in the case of csv files, this means that you will get raw csv, not a nice table. If you require nicely tabulated and formatted data, use a spreadsheet to open the created csv file.","title":"Output"},{"location":"how_to_use_gui_damage/#the-help-menu","text":"Damage help : takes you to this page. Obviously, this requires an internet connection, but what doesn\u2019t these days Credits and Details : Developer information as well as links to the source code.","title":"The Help menu"}]}